{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac16fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Import pandas for .read_html() function\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51bcd9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Driver [C:\\Users\\Gary Laptop\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# set your executable path then set up the URL\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "732edea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign the url and instruct the browser to visit it\n",
    "# Visit the mars nasa news site\n",
    "url = 'https://redplanetscience.com'\n",
    "browser.visit(url)\n",
    "# Optional delay for loading the page\n",
    "browser.is_element_present_by_css('div.list_text', wait_time=1)\n",
    "\n",
    "# With the following line, browser.is_element_present_by_css('div.list_text', wait_time=1), we are \n",
    "# accomplishing two things.\n",
    "\n",
    "# One is that we're searching for elements with a specific combination of tag (div) and attribute (list_text). As an\n",
    "# example, ul.item_list would be found in HTML as <ul class=\"item_list\">.\n",
    "\n",
    "# Secondly, we're also telling our browser to wait one second before searching for components. \n",
    "# The optional delay is useful because sometimes dynamic pages take a little while to load, especially if they are\n",
    "# image-heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbeeaa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the HTML parser:\n",
    "html = browser.html\n",
    "news_soup = soup(html, 'html.parser')\n",
    "slide_elem = news_soup.select_one('div.list_text')\n",
    "\n",
    "# Notice how we've assigned slide_elem as the variable to look for the <div /> tag and its descendent \n",
    "# (the other tags within the <div /> element)? This is our parent element. This means that this element holds all of\n",
    "# the other elements within it, and we'll reference it when we want to filter search results even further. The . is used \n",
    "# for selecting classes, such as list_text, so the code 'div.list_text' pinpoints the <div /> tag with the\n",
    "# class of list_text. CSS works from right to left, such as returning the last item on the list instead of the first. \n",
    "# Because of this, when using select_one, the first matching element returned will be a <li /> element with a class of\n",
    "# slide and all nested elements within it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa62bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"content_title\">NASA's Mars 2020 Heads Into the Test Chamber</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After opening the page in a new browser, right-click to inspect and activate your DevTools. Then search for\n",
    "# the HTML components you'll use to identify the title and paragraph you want\n",
    "# What we will search is: class = “content_title”\n",
    "\n",
    "# We'll want to assign the title and summary text to variables we'll reference later\n",
    "# begin our scraping:\n",
    "slide_elem.find('div', class_='content_title')\n",
    "\n",
    "# In this line of code, we chained .find onto our previously assigned variable, slide_elem. When we do this,\n",
    "# we're saying, \"This variable holds a ton of information, so look inside of that information to find this specific\n",
    "# data.\" The data we're looking for is the content title, which we've specified by saying, \"The specific data is in \n",
    "# a <div /> with a class of 'content_title'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a485bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"NASA's Mars 2020 Heads Into the Test Chamber\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The title is in that mix of HTML in our output—that's awesome! But we need to get just the text, and the extra\n",
    "# HTML stuff isn't necessary. \n",
    "\n",
    "# Use the parent element to find the first `a` tag and save it as `news_title`\n",
    "news_title = slide_elem.find('div', class_='content_title').get_text()\n",
    "news_title\n",
    "\n",
    "# We've added something new to our .find() method here: .get_text(). When this new method is chained onto .find(), only \n",
    "# the text of the element is returned. The code above, for example, would return only the title of the news article and not\n",
    "# any of the HTML tags or elements\n",
    "\n",
    "# Once executed, the result is the most recent title published on the website. When the website is updated and a new \n",
    "# article is posted, when our code is run again, it will return that article instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61512b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this time-lapse video taken at JPL, engineers move the Mars 2020 rover into a large vacuum chamber for testing in Mars-like environmental conditions.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next we need to add the summary text.\n",
    "# Use the DevTools selector tool and select the article summary (teaser), then check to see which tag is highlighted.\n",
    "\n",
    "# We know that \"article_teaser_body\" is the right class name, but when we search for it, there is more than one \n",
    "# result. What now?\n",
    "\n",
    "# That's okay. There will be many matches because there are many articles, each with a tag of <div /> and a class of\n",
    "# article_teaser_body. We want to pull the first one on the list, not a specific one, so more than 10 results is fine. \n",
    "# In this case, if our scraping code is too specific, we'd pull only that article summary instead of the most recent.\n",
    "\n",
    "# Because new articles are added to the top of the list, and we only need the most recent one, our search leads us to the\n",
    "# first article.\n",
    "\n",
    "# There are two methods used to find tags and attributes with BeautifulSoup:\n",
    "\n",
    "# .find() is used when we want only the first class and attribute we've specified.\n",
    "# .find_all() is used when we want to retrieve all of the tags and attributes.\n",
    "# For example, if we were to use .find_all() instead of .find() when pulling the summary, we would retrieve all of\n",
    "# the summaries on the page instead of just the first one.\n",
    "\n",
    "# Use the parent element to find the paragraph text\n",
    "news_p = slide_elem.find('div', class_='article_teaser_body').get_text()\n",
    "news_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c0b59",
   "metadata": {},
   "source": [
    "# Our next step scraping code will be to gather the featured images from the Jet Propulsion Laboratory's Space \n",
    "# Images (Links to an external site.) webpage. In your Jupyter notebook, use markdown to separate the article scraping \n",
    "# from the image scraping.\n",
    "\n",
    "### Featured Images\n",
    "\n",
    "# change the format of the code cell to \"Markdown.\"\n",
    "# You can access the cell formatting feature by using a drop-down menu at the top of the notebook. It's currently \n",
    "# set to \"Code,\" so click the down arrow to toggle the drop-down menu and select \"Markdown\" instead.\n",
    "# This would normally just be a cell that says featured images and is changed to markdown, but I have these notes to remember it. No code should go in this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9736d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit URL\n",
    "url = 'https://spaceimages-mars.com'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09968f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we want to click the \"Full Image\" button. This button will direct our browser to an image slideshow.\n",
    "# Let's take a look at the button's HTML tags and attributes with the DevTools\n",
    "# <button class=\"btn btn-outline-light\"> FULL IMAGE</button>\n",
    "# This is a fairly straightforward HTML tag: the <button> element has a two \n",
    "# classes (btn and btn-outline-light) and a string reading \"FULL IMAGE\".\n",
    "\n",
    "# First, let's use the dev tools to search for all the button elements. There are 3 of them.\n",
    "# Since there are only three buttons, and we want to click the full-size image button, we can go ahead and use\n",
    "# the HTML tag in our code.\n",
    "\n",
    "# Find and click the full image button\n",
    "full_image_elem = browser.find_by_tag('button')[1]\n",
    "full_image_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66d1a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the new page loaded onto our automated browser, it needs to be parsed so we can continue and scrape t\n",
    "# he full-size image URL\n",
    "\n",
    "# Parse the resulting html with soup\n",
    "html = browser.html\n",
    "img_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3232efc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image/featured/mars2.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we need to find the relative image URL. In our browser (make sure you're on the same page as the automated one),\n",
    "# activate your DevTools again. This time, let's find the image link for that image. \n",
    "\n",
    "# We want to pull the most recently posted image for our web app\n",
    "# It's important to note that the value of the src will be different every time the page is updated, so we\n",
    "# can't simply record the current value—we would only pull that image each time the code is executed, instead of the most\n",
    "# recent one.\n",
    "\n",
    "# We'll use the image tag and class (<img />and fancybox-img) to build the URL to the full-size image. \n",
    "\n",
    "# Find the relative image url\n",
    "img_url_rel = img_soup.find('img', class_='fancybox-image').get('src')\n",
    "img_url_rel\n",
    "\n",
    "# We've done a lot with that single line.\n",
    "    # An img tag is nested within this HTML, so we've included it.\n",
    "    # .get('src') pulls the link to the image.\n",
    "    \n",
    "# What we've done here is tell BeautifulSoup to look inside the <img /> tag for an image with a class of fancybox-image. \n",
    "# Basically we're saying, \"This is where the image we want lives—use the link that's inside these tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caf50ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://spaceimages-mars.com/image/featured/mars2.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we copy and paste this link into a browser, it won't work. This is because it's only a partial link, as the base\n",
    "# URL isn't included.\n",
    "\n",
    "# Let's add the base URL to our code.\n",
    "# Use the base URL to create an absolute URL\n",
    "img_url = f'https://spaceimages-mars.com/{img_url_rel}'\n",
    "img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d618fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mars</th>\n",
       "      <th>Earth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mars - Earth Comparison</th>\n",
       "      <td>Mars</td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter:</th>\n",
       "      <td>6,779 km</td>\n",
       "      <td>12,742 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.39 × 10^23 kg</td>\n",
       "      <td>5.97 × 10^24 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance from Sun:</th>\n",
       "      <td>227,943,824 km</td>\n",
       "      <td>149,598,262 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length of Year:</th>\n",
       "      <td>687 Earth days</td>\n",
       "      <td>365.24 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature:</th>\n",
       "      <td>-87 to -5 °C</td>\n",
       "      <td>-88 to 58°C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Mars            Earth\n",
       "description                                              \n",
       "Mars - Earth Comparison             Mars            Earth\n",
       "Diameter:                       6,779 km        12,742 km\n",
       "Mass:                    6.39 × 10^23 kg  5.97 × 10^24 kg\n",
       "Moons:                                 2                1\n",
       "Distance from Sun:        227,943,824 km   149,598,262 km\n",
       "Length of Year:           687 Earth days      365.24 days\n",
       "Temperature:                -87 to -5 °C      -88 to 58°C"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We've chosen to collect our data from Mars Facts (Links to an external site.), so let's visit the webpage to look at\n",
    "# what we'll be working with. We already have a great photo and an article, so all we want from this page is the\n",
    "# table. Our plan is to display it as a table on our own web app, so keeping the current HTML table format is important.\n",
    "\n",
    "# Let's look at the webpage again, this time using our DevTools. All of the data we want is in a <table /> tag. HTML\n",
    "# code used to create a table looks fairly complex, but it's really just breaking down and naming each component.\n",
    "\n",
    "# Tables in HTML are basically made up of many smaller containers. The main container is the <table /> tag. Inside \n",
    "# the table is <tbody />, which is the body of the table—the headers, columns, and rows.\n",
    "\n",
    "# <tr /> is the tag for each table row. Within that tag, the table data is stored in <td /> tags. This is where\n",
    "# the columns are established.\n",
    "\n",
    "# Instead of scraping each row, or the data in each <td />, we're going to scrape the entire table \n",
    "# with Pandas' .read_html() function.\n",
    "\n",
    "# At the top of your Jupyter Notebook, add import pandas as pd to the dependencies and rerun the cell. This \n",
    "# way, we'll be able to use this new function without generating an error\n",
    "\n",
    "# Turn the table into a dataframe basically\n",
    "df = pd.read_html('https://galaxyfacts-mars.com')[0]\n",
    "df.columns=['description', 'Mars', 'Earth']\n",
    "df.set_index('description', inplace=True)\n",
    "df\n",
    "\n",
    "# df = pd.read_htmldf = pd.read_html('https://galaxyfacts-mars.com')[0] With this line, we're creating a new DataFrame \n",
    "# from the HTML table. The Pandas function read_html() specifically searches for and returns a list of tables found in the\n",
    "# HTML. By specifying an index of 0, we're telling Pandas to pull only the first table it encounters, or the first item \n",
    "# in the list. Then, it turns the table into a DataFrame.\n",
    "\n",
    "# df.columns=['description', 'Mars', 'Earth'] Here, we assign columns to the new DataFrame for additional clarity.\n",
    "\n",
    "# df.set_index('description', inplace=True) By using the .set_index() function, we're turning the Description column\n",
    "# into the DataFrame's index. inplace=True means that the updated index will remain in place, without having to reassign \n",
    "# the DataFrame to a new variable.\n",
    "\n",
    "# Now, when we call the DataFrame, we're presented with a tidy, Pandas-friendly representation of the HTML table we \n",
    "# were just viewing on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "756baf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Mars</th>\\n      <th>Earth</th>\\n    </tr>\\n    <tr>\\n      <th>description</th>\\n      <th></th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Mars - Earth Comparison</th>\\n      <td>Mars</td>\\n      <td>Earth</td>\\n    </tr>\\n    <tr>\\n      <th>Diameter:</th>\\n      <td>6,779 km</td>\\n      <td>12,742 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg</td>\\n      <td>5.97 × 10^24 kg</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2</td>\\n      <td>1</td>\\n    </tr>\\n    <tr>\\n      <th>Distance from Sun:</th>\\n      <td>227,943,824 km</td>\\n      <td>149,598,262 km</td>\\n    </tr>\\n    <tr>\\n      <th>Length of Year:</th>\\n      <td>687 Earth days</td>\\n      <td>365.24 days</td>\\n    </tr>\\n    <tr>\\n      <th>Temperature:</th>\\n      <td>-87 to -5 °C</td>\\n      <td>-88 to 58°C</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do we add the DataFrame to a web application? Our data is live—if the table is updated, then we want\n",
    "# that change to appear in our app\n",
    "\n",
    "# Thankfully, Pandas also has a way to easily convert our DataFrame back into HTML-ready code using\n",
    "# the .to_html() function:\n",
    "\n",
    "df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09342635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the session\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527604a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export to Python\n",
    "\n",
    "# we can't automate the scraping using the Jupyter Notebook. To fully automate it, it will need to be \n",
    "# converted into a .py file.\n",
    "\n",
    "# The next step in making this an automated process is to download the current code into a Python file. It won't \n",
    "# transition over perfectly, we'll need to clean it up a bit, but it's an easier task than copying each \n",
    "# cell and pasting it over in the correct order\n",
    "\n",
    "# The Jupyter ecosystem is an extremely versatile tool. We already know many of its great functions, such as the\n",
    "# different libraries that work well with it and also how easy it is to troubleshoot code. Another feature is being \n",
    "# able to download the notebook into different formats.\n",
    "\n",
    "# There are several formats available, but we'll focus on one by downloading to a Python file.\n",
    "\n",
    "    # 1. While your notebook is open, navigate to the top of the page to the Files tab.\n",
    "    \n",
    "    # 2. From here, scroll down to the \"Download as\" section of the drop-down menu.\n",
    "    \n",
    "    # 3. Select \"Python (.py)\" from the next menu to download the code\n",
    "    \n",
    "    # 4. If you get a warning about downloading this type of file, click \"Keep\" to continue the download.\n",
    "    \n",
    "    # 5. Navigate to your Downloads folder and open the new file. A brief look at the first lines of code shows us\n",
    "    # that the code wasn't the only thing to be ported over. The number of times each cell has been run is also there, \n",
    "    # for example\n",
    "    \n",
    "    # 6. Clean up the code by removing unnecessary blank spaces and comments. When you're done tidying up the code,\n",
    "    # make sure you save it in your working folder with your notebook code as scraping.py. You can also test the script by\n",
    "    # running it through your terminal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
